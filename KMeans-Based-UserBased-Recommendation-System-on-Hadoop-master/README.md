# KMeans Based UserBased Recommendation System on Hadoop

This is a KMeans Based UserBased recommendation system built on Hadoop. In order to handle large user volume, 
I first implement the KMeans clustering algorithm on Hadoop to group users into clusters and then implement userbased recommendation.  
Except utilizing the VectorWritable class from the mahout library, I self-design the whole framework.  :see_no_evil: 
I believe it is easy to understand adn use.

##Data
This project was based on the famous Million Song Dataset. The Million Song Dataset is a freely available collection of metadata for millions contemporary songs. 
The complete datasets consist of 7 subsets of derived features. The total size of the dataset is 280GB.
The subset of data used in the challenge is called Taste Profile Subset that consists of more than 48 million triplets gathered from users' listening history. 
The triplets have 3 fields: user, song, counts. 
In total, the data consists of about 1.2 million users and covers more than 380,000 songs in MSD. 
Taste Profile Subset is used for collaborative filtering in this project.  
You can get the dataset here: [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/)  

##Data preparetion
The whole taste profile dataset contains 1,019,318 unique users, 384,546 unique MSD songs 
and totally 48,373,586 in user-song-play count triplets format.
What I do is to make a set of unique users from the whole triplets, 
hash the unique users set using numeric value and finally match back to the original dataset. 
The process for the unique song set is the same.

##Basic stage description: KMeans
**Stage One:** Generalise User-Item Preference vectors  
Input: (userID, songID) -> Output: (userID, {song1: 1.0, song2: 1.0, ...})  
Here we utilise the VectorWritable class from the Mahout library to store the User-Item Preference vector. In order to optimise the whole process, we save all VectorWritable related outputs as SequenceFile for further use.  
**Stage Two:** Randomly choose k User-Item Preference vec- tors as initial centres After initialisation, 
initialised cen- tres and User-Item Preference vectors are saved in the path Job 0.  
Centres: (centreID, User-Item Preference vector) Clusters: (clusterID, User-Item Preference vector)    
**Stage Three:** Update centres and cluster assignment until converged Each iteration saves updated centres and cluster assignment to the path Job JobID.  
Job 0 ->Job 1 -> Job 2 -> Job ...  
**Stage Four:** Save the final centres and clusters for User- Based collaborative filtering. 
Final centres vectors and User- Item Preference vectors are saved in a path called Result. 
(User-Item Preference vectors are broken into small files sep- arated by clusterIDs).  
Result: (Centres, Cluster 1, Cluster 2, Cluster 3, ..., Cluster ...)  

##Basic stage description: UserBased
**Stage One:** Generalise target User-Item Preference vectors  
**Stage Two:** Calculate similarity between target user and each user cluster centre Based on the similarities, 
enough number of top most similar user clusters are chosen for fur- ther use. 
The number of users needed from each selected user cluster should be specified. 
Sometimes a user cluster may contain more number of users than we need. 
In that case, we just randomly choose a user subset from the cluster.   
Output: (centerID@centerID, sim@similarity, num@number of users needed)  
**Stage Three:** Generate recommendation lists based on two level similarity Users from the chosen clusters 
are used as the similar users for the target user. 
In order to generate more reasonable recommendation lists, 
similarity between target user and each similar user are calculated and then used 
as scaling weight for each recommend item. In sum, score of each item is 
calculated based on two level similarity computed as target user-user cluster 
similarity times target user-user similarity. Cosine similarity is used here. 
Besides, songs already listened by the target user are filtered out in this stage.  
Output: (userID@songID, SongScore)  
**Stage Four:** Aggregate the scores of songs for each user   
Output: (userID@songID, Aggregated SongScore)  
**Stage Five:** Sort and recommend the top-N songs In order to do the performance evaluation, 
we have to recommend top-10000 songs for each target user. 
It is obvious that there must be some target users donâ€™t have 
enough recommended songs from their similar users. In terms of this situation, 
we append popular songs generated by the baseline to the recommendation list until the length of the list reaches 10000.  
